{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d13cabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Lenovo ThinkPad X280\\\\Downloads\\\\End-to-end-Medical-Chatbot-Generative-AI\\\\research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67e36fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo ThinkPad X280\\anaconda3\\envs\\medibot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from transformers import pipeline\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0ec45a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa1420be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Lenovo ThinkPad X280\\\\Downloads\\\\End-to-end-Medical-Chatbot-Generative-AI'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30771cb",
   "metadata": {},
   "source": [
    "### **I. Load PDF & Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d13677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_file(data):\n",
    "    loader = DirectoryLoader(data, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd9bfdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    return text_splitter.split_documents(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66d780b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to access: C:\\Users\\Lenovo ThinkPad X280\\Downloads\\End-to-end-Medical-Chatbot-Generative-AI\\Data\n",
      "Directory C:\\Users\\Lenovo ThinkPad X280\\Downloads\\End-to-end-Medical-Chatbot-Generative-AI\\Data exists!\n",
      "Jumlah potongan teks: 5859\n"
     ]
    }
   ],
   "source": [
    "project_dir = r\"C:\\Users\\Lenovo ThinkPad X280\\Downloads\\End-to-end-Medical-Chatbot-Generative-AI\"\n",
    "data_dir = os.path.join(project_dir, 'Data')\n",
    "\n",
    "print(\"Trying to access:\", data_dir)\n",
    "if not os.path.exists(data_dir):\n",
    "    print(f\"Directory {data_dir} does not exist!\")\n",
    "else:\n",
    "    print(f\"Directory {data_dir} exists!\")\n",
    "    extracted_data = load_pdf_file(data=data_dir)\n",
    "    text_chunks = text_split(extracted_data)\n",
    "    print(\"Jumlah potongan teks:\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ced0c36",
   "metadata": {},
   "source": [
    "### **II. Download Embedding & Create FAISS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f624b1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hugging_face_embeddings():\n",
    "    return HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f179d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo ThinkPad X280\\AppData\\Local\\Temp\\ipykernel_13740\\1317837547.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  return HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensi embedding: 384\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_hugging_face_embeddings()\n",
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Dimensi embedding:\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2420627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save FAISS index\n",
    "vectorstore = FAISS.from_documents(text_chunks, embeddings)\n",
    "vectorstore.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caf482ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load back FAISS index\n",
    "vectorstore = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1eb666",
   "metadata": {},
   "source": [
    "### **III. Load LLM of Hugging Face**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97bdec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "qa_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\", device=0)  # pakai GPU jika ada\n",
    "\n",
    "def hf_llm(prompt):\n",
    "    result = qa_pipeline(prompt, max_new_tokens=256, do_sample=False)\n",
    "    return result[0]['generated_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0982ab",
   "metadata": {},
   "source": [
    "### **IV. Create Promt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53e5352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are a medical assistant specialized in dermatology. \"\n",
    "    \"Using only the context provided below, answer the user question precisely. \"\n",
    "    \"Do not use prior knowledge or guess. If the answer is not in the context, reply: 'Sorry, I couldn't find the answer in the documents.' \"\n",
    "    \"Answer in maximum 3 short sentences.\"\n",
    "    \"\\n\\n\"\n",
    "    \"Context:\\n{context}\"\n",
    "    \"\\n\\nQuestion: {input}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5207d40",
   "metadata": {},
   "source": [
    "### **V. Cleaning Helper**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b899f839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace('\\n', ' ').strip()\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ef1cba",
   "metadata": {},
   "source": [
    "### **VI. Chat History**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "311e0b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []\n",
    "\n",
    "def save_chat_history(user_input, response):\n",
    "    chat_history.append({\"question\": user_input, \"answer\": response})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1c8451",
   "metadata": {},
   "source": [
    "### **VII. Final Chain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9f8ca15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_hf_chain(input_text):\n",
    "    docs = retriever.invoke(input_text)\n",
    "    context = \"\\n\\n\".join([clean_text(doc.page_content) for doc in docs])\n",
    "    prompt_filled = system_prompt.replace(\"{context}\", context).replace(\"{input}\", input_text)\n",
    "    answer = hf_llm(prompt_filled)\n",
    "    save_chat_history(input_text, answer)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fdc070",
   "metadata": {},
   "source": [
    "### **VIII. Data Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3afe6f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      " a common skin disease characterized by pimples on the face, chest, and back. It occurs when the pores of the skin become clogged with oil, dead skin cells, and bacteria.\n"
     ]
    }
   ],
   "source": [
    "response = custom_hf_chain(\"What is Acne?\")\n",
    "print(\"\\nAnswer:\\n\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medibot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
